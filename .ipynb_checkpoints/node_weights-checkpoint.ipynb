{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longitude is x, latitude is y\n",
    "\n",
    "G = ox.graph_from_place('San Francisco, CA, USA', network_type='drive')\n",
    "nodes = ox.graph_to_gdfs(G, edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cols = list(nodes.columns)\n",
    "temp_cols[temp_cols.index('x')] = 'lng'; temp_cols[temp_cols.index('y')] = 'lat'\n",
    "nodes.columns = temp_cols\n",
    "nodes = nodes.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping from original node number names to new node number names\n",
    "\n",
    "node_name_map = {}; node_name_map_inv = {}\n",
    "node_og = list(nodes.index)\n",
    "num_nodes = len(node_og)\n",
    "for i in range(num_nodes):\n",
    "    node_name_map[i] = node_og[i]\n",
    "    node_name_map_inv[node_og[i]] = i\n",
    "nodes.index = range(nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_police_stops = pd.read_csv('ca_san_francisco_2019_08_13.csv')\n",
    "df_police_stops = df_police_stops[pd.notnull(df_police_stops['lng'])]\n",
    "df_police_stops = df_police_stops[pd.notnull(df_police_stops['lat'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(long1, lat1, long2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between an array of points to a single point\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    long1, lat1, long2, lat2 = map(np.radians, [long1, lat1, long2, lat2])\n",
    "\n",
    "    dlon = long2 - long1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/903373\n",
      "10000/903373\n",
      "20000/903373\n",
      "30000/903373\n",
      "40000/903373\n",
      "50000/903373\n",
      "60000/903373\n",
      "70000/903373\n",
      "80000/903373\n",
      "90000/903373\n",
      "100000/903373\n",
      "110000/903373\n",
      "120000/903373\n",
      "130000/903373\n",
      "140000/903373\n",
      "150000/903373\n",
      "160000/903373\n",
      "170000/903373\n",
      "180000/903373\n",
      "190000/903373\n",
      "200000/903373\n",
      "210000/903373\n",
      "220000/903373\n",
      "230000/903373\n",
      "240000/903373\n",
      "250000/903373\n",
      "260000/903373\n",
      "270000/903373\n",
      "280000/903373\n",
      "290000/903373\n",
      "300000/903373\n",
      "310000/903373\n",
      "320000/903373\n",
      "330000/903373\n",
      "340000/903373\n",
      "350000/903373\n",
      "360000/903373\n",
      "370000/903373\n",
      "380000/903373\n",
      "390000/903373\n",
      "400000/903373\n",
      "410000/903373\n",
      "420000/903373\n",
      "430000/903373\n",
      "440000/903373\n",
      "450000/903373\n",
      "460000/903373\n",
      "470000/903373\n",
      "480000/903373\n",
      "490000/903373\n",
      "500000/903373\n",
      "510000/903373\n",
      "520000/903373\n",
      "530000/903373\n",
      "540000/903373\n",
      "550000/903373\n",
      "560000/903373\n",
      "570000/903373\n",
      "580000/903373\n",
      "590000/903373\n",
      "600000/903373\n",
      "610000/903373\n",
      "620000/903373\n",
      "630000/903373\n",
      "640000/903373\n",
      "650000/903373\n",
      "660000/903373\n",
      "670000/903373\n",
      "680000/903373\n",
      "690000/903373\n",
      "700000/903373\n",
      "710000/903373\n",
      "720000/903373\n",
      "730000/903373\n",
      "740000/903373\n",
      "750000/903373\n",
      "760000/903373\n",
      "770000/903373\n",
      "780000/903373\n",
      "790000/903373\n",
      "800000/903373\n",
      "810000/903373\n",
      "820000/903373\n",
      "830000/903373\n",
      "840000/903373\n",
      "850000/903373\n",
      "860000/903373\n",
      "870000/903373\n",
      "880000/903373\n",
      "890000/903373\n",
      "900000/903373\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from time import time\n",
    "\n",
    "coords = nodes[['lng', 'lat']].values\n",
    "long1 = np.array(coords)[:, 0]\n",
    "lat1 = np.array(coords)[:, 1]\n",
    "batch_size = 500\n",
    "police_stops = {}\n",
    "m = df_police_stops.shape[0]\n",
    "for i in range(0, m, batch_size):\n",
    "    if i % 10000 == 0: print('%d/%d' % (i, m))\n",
    "    if i + batch_size >= m:\n",
    "        stop_coords = df_police_stops[['lng', 'lat']].values[i:]\n",
    "    else:\n",
    "        stop_coords = df_police_stops[['lng', 'lat']].values[i:i+batch_size]\n",
    "    \n",
    "    associated_nodes = np.array([haversine_np(long1, lat1, long2, lat2) for (long2, lat2) in stop_coords]).argmin(axis=1)\n",
    "#     associated_nodes = dist.cdist(coords, stop_coords).argmin(axis=0)\n",
    "    for idx in range(len(associated_nodes)):\n",
    "        police_stops[associated_nodes[idx]] = police_stops.get(associated_nodes[idx], []) + [df_police_stops.iloc[i+idx].values]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edges = 0\n",
    "rewards = {}\n",
    "worse_reward = -100000\n",
    "for node in range(num_nodes):\n",
    "    edges = list(G[nodes.iloc[node]['osmid']]) # G has the edges as the original node numbers thats what osmid is\n",
    "    max_edges = max(max_edges, len(edges))\n",
    "    # convert the edges from original names to new renamed, sorted is just to keep actions in some kind of order\n",
    "    # for example the 1st action will always be the first chronological node based on naming\n",
    "    edges = sorted([node_name_map_inv[edge] for edge in edges]) \n",
    "    # set reward of going to this edge equal to negative number of police stops at this node\n",
    "    # if there are no police stops at the edge set reward to 0\n",
    "    rewards[node] = [-len(police_stops[edge]) if edge in police_stops else 0 for edge in edges]\n",
    "    \n",
    "# fill terrible reward for nodes that have less total actions, encodes impossible actions essentially\n",
    "for node in range(num_nodes):\n",
    "    curr_actions = rewards[node]\n",
    "    rewards[node] = curr_actions + [worse_reward]*(max_edges-len(curr_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('nodes_with_police_stops.pickle', 'wb') as handle:\n",
    "    pickle.dump(police_stops, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('police_stop_rewards.pickle', 'wb') as handle:\n",
    "    pickle.dump(rewards, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nodes_with_police_stops.pickle', 'rb') as handle:\n",
    "    police_stops = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = pd.read_csv('Traffic_Calming_Point_Features_092014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = traffic_df['the_geom'].values\n",
    "buffer = 7\n",
    "points  = np.array([(float(i[i.find('(')+1:i[buffer:].find(' ')+buffer]), float(i[i[buffer:].find(' ')+1+buffer:i.find(')')])) for i in h])\n",
    "long, lat = points[:, 0], points[:, 1]\n",
    "del traffic_df['the_geom']\n",
    "traffic_df['lng'] = long\n",
    "traffic_df['lat']  = lat\n",
    "# [traffic_df['the_geom'].find('(')+1:traffic_df['the_geom'].find(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/453\n",
      "100/453\n",
      "200/453\n",
      "300/453\n",
      "400/453\n"
     ]
    }
   ],
   "source": [
    "coords = nodes[['lng', 'lat']].values\n",
    "long1 = np.array(coords)[:, 0]\n",
    "lat1 = np.array(coords)[:, 1]\n",
    "batch_size = 100\n",
    "traffic_calmers = {}\n",
    "m = traffic_df.shape[0]\n",
    "for i in range(0, m, batch_size):\n",
    "    if i % 100 == 0: print('%d/%d' % (i, m))\n",
    "    if i + batch_size >= m:\n",
    "        stop_coords = traffic_df[['lng', 'lat']].values[i:]\n",
    "    else:\n",
    "        stop_coords = traffic_df[['lng', 'lat']].values[i:i+batch_size]\n",
    "    \n",
    "    associated_nodes = np.array([haversine_np(long1, lat1, long2, lat2) for (long2, lat2) in stop_coords]).argmin(axis=1)\n",
    "#     associated_nodes = dist.cdist(coords, stop_coords).argmin(axis=0)\n",
    "    for idx in range(len(associated_nodes)):\n",
    "        traffic_calmers[associated_nodes[idx]] = traffic_calmers.get(associated_nodes[idx], []) + [traffic_df.iloc[i+idx].values]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([6786, 2615, 1310, 3325, 3222, 1945, 1944, 1518, 2426, 7898, 3874, 3873, 7896, 5090, 5902, 4028, 6613, 8655, 2990, 2981, 4733, 9249, 6802, 6551, 1720, 5640, 3207, 818, 8488, 4933, 6464, 3761, 4249, 2341, 4308, 4721, 5997, 4717, 4639, 5420, 1969, 1971, 9599, 9603, 5477, 3375, 3345, 6797, 8841, 7250, 7251, 7252, 7253, 7254, 7255, 2734, 2739, 513, 9317, 9318, 5397, 5800, 887, 886, 6077, 9116, 6260, 5825, 5257, 7373, 7319, 8401, 3616, 1938, 6532, 2613, 7433, 5904, 4816, 4156, 4157, 5365, 5225, 7035, 8483, 8590, 9255, 7186, 890, 4732, 8405, 5903, 1914, 8346, 6378, 5072, 8477, 5725, 4114, 2244, 8289, 4799, 8164, 2726, 9247, 1390, 6531, 8204, 8467, 4653, 1117, 3058, 7443, 7438, 7796, 8519, 8520, 6109, 5930, 8436, 4514, 8410, 8260, 8261, 4755, 5724, 6000, 4718, 5535, 267, 1426, 6181, 6417, 2951, 8486, 6901, 6933, 6915, 6935, 1028, 4535, 3992, 510, 4536, 2449, 7174, 364, 5948, 7126, 3278, 3464, 1271, 5348, 444, 440, 438, 436, 435, 431, 429, 428, 422, 419, 7234, 9540, 6550, 7693, 1407, 9157, 9158, 4772, 2234, 2557, 5238, 5522, 8240, 5441, 4648, 2701, 5349, 6437, 2695, 9021, 8389, 9023, 5378, 5379, 1690, 3831, 6443, 4521, 6211, 964, 76, 3189, 675, 1108, 1966, 6103, 9314, 2469, 8609, 4680, 6685, 3306, 6682, 4711, 8459, 6292, 4104, 1863, 781, 5537, 4980, 4978, 7722, 142, 7476, 2378, 8213, 4265, 4849, 9414, 4761, 9355, 7564, 2790, 8444, 2925, 6593, 5876, 2947, 5371, 8958, 8140, 6617, 5346, 5740, 338, 1030, 1488, 6081, 3289, 337, 5896, 4363, 3615, 8208, 3586, 8214, 1610, 2641, 7288, 4189, 415, 416, 5778, 739, 738, 1012, 2094, 2095, 3747, 3564, 1008, 1009, 2442, 3566, 3567, 2441, 3765, 3539, 3763, 3274, 823, 2467, 3767, 3384, 5872, 6043, 553, 6016, 9053, 1418, 8985, 8987, 940, 8176, 8173, 3483, 2725, 6039, 3757, 5626, 4004, 1974, 1216, 512, 7289, 269, 762, 342, 544, 547, 548, 1858, 1551, 3392, 7282, 9518, 2692, 5831, 6114, 1223, 7529, 5617, 5355, 8873, 8876, 7058, 8228, 8377, 4906, 842, 1733, 1779, 3746, 239, 5009, 557, 7071, 4302, 3859, 2841, 4869, 899, 5236, 1638, 3439, 400, 6517, 8539, 5237, 6348, 7601, 2295, 6252, 9328, 1478, 6197, 6198, 4006, 1276, 1277, 2748, 455, 2750, 494, 3438, 6472, 2826, 6466, 1529, 3705, 8179, 1572, 1601, 481, 5627, 516, 2481, 5615, 7762, 2622])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_calmers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([15, nan, nan, nan, nan, 0, nan, 0, 4252000.0, 'COLERIDGE ST',\n",
       "        'POWERS AVE', 'COSO AVE', 0, 0, nan, 0, 'Speed Bump',\n",
       "        -122.41823377796212, 37.74597274096357], dtype=object)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_calmers[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat                                 37.7461\n",
       "lng                                -122.418\n",
       "osmid                              65288014\n",
       "highway                                 NaN\n",
       "ref                                     NaN\n",
       "geometry    POINT (-122.4181898 37.7460833)\n",
       "Name: 400, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.iloc[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def calculate_transition(sPrime, state, reward):\n",
    "    if reward == -100000:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0/6.0\n",
    "\n",
    "iteration = 1\n",
    "discount = 0.95\n",
    "U = pd.DataFrame(np.zeros((num_nodes, 1)))\n",
    "while True:\n",
    "    U_prev = U.copy()\n",
    "    #algo 4.3 in sequential problems textbook\n",
    "    for node in range(num_nodes):\n",
    "        node_rewards = rewards[node]\n",
    "        U.iloc[node] = max(r + discount*sum(calculate_transition(sPrime, node, r)*U_prev.iloc[sPrime] \n",
    "            for sPrime in range(num_nodes))\n",
    "                for r in node_rewards)\n",
    "    difference = np.square(U.sub(U_prev)).values.sum()\n",
    "    if difference < 1.0:\n",
    "        break\n",
    "    iteration += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
